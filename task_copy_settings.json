{
    "model_tag": "transformer",
    "is_train": false,
    "model_hyper_params": {},
    "use_metric_in_graph": true,
    "log_device": false,
    "gpu_mem_growth": true,
    "soft_placement": true,
    "gpu_available": "0",
    "gpu_batch_split": [
        16,
        20
    ],
    "num_epochs": 100,
    "batch_size": 36,
    "batch_size_eval": 6,
    "max_batches_eval": 20,
    "reg_lambda": 0.0,
    "reg_exclusions": [
        "embedding",
        "bias",
        "layer_norm",
        "LayerNorm"
    ],
    "grad_clip": 0.0,
    "keep_prob": 0.9,
    "optimizer_type": "adam",
    "momentum": 0.9,
    "learning_rate_base": 0.001,
    "learning_rate_minimum": 1e-06,
    "warmup_steps": 1000,
    "decay_steps": 5000,
    "decay_rate": 0.99,
    "staircase": true,
    "check_period_batch": 100,
    "valid_period_batch": 100,
    "base_dir": "./task_copy_results",
    "model_dir": null,
    "model_dir_best": null,
    "model_name": null,
    "pb_file": null,
    "log_dir": null,
    "log_path": null,
    "task": "copy",
    "tokens_file": "./vocab/vocab_tokens.txt",
    "min_seq_len": 1,
    "max_seq_len": 12,
    "emb_dim": 128,
    "emb_tune": 1,
    "posi_emb_dim": 128,
    "num_layers": 6,
    "num_heads": 8,
    "num_units": 16,
    "dim_all": 128,
    "dim_model": 128,
    "dim_ffm": 256,
    "activation": "gelu",
    "beam_width": 1,
    "max_len_decoding": 12,
    "start_symbol_id": 2,
    "with_bucket": false,
    "label_smoothing": 0.01
}